{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb307e2b-875a-4ad0-b3e7-205c49de7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "567c3892-6fca-4550-afd7-0aa6e28866cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38b93a47-c020-4615-9ca8-19db6d452a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_datetime(timestamp_series: pd.Series) -> list:\n",
    "    datetimes = []\n",
    "    for i in timestamp_series:\n",
    "        ts = int(i)\n",
    "        # Check if timestamp is in microseconds (usually more than 13 digits)\n",
    "        if ts > 1e13:  \n",
    "            ts = ts / 1_000_000  # Convert from microseconds\n",
    "        else:\n",
    "            ts = ts / 1_000  # Convert from milliseconds\n",
    "        datetimes.append(dt.fromtimestamp(ts))\n",
    "    return datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687665dd-7b25-4984-8bcb-642f368c0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = pd.read_csv('combined_BTC.csv').drop_duplicates().iloc[1:]\n",
    "btc['Open time'] = timestamp_to_datetime(btc['Open time'])\n",
    "btc['Close time']= timestamp_to_datetime(btc['Close time'])\n",
    "# Convert columns to float\n",
    "btc[['Open', 'High', 'Low', 'Close', 'Volume']] = btc[['Open', 'High', 'Low', 'Close', 'Volume']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33f5915-cc99-492d-b84b-71cb5077f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = btc.sort_values('Open time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2f64c04-a5a2-46f5-9e79-7b3bedec2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = pd.read_csv('combined_eth.csv').drop_duplicates().iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2476f62-9ec8-464d-8e2a-18243bf1a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth['Open time'] = timestamp_to_datetime(eth['Open time'])\n",
    "eth['Close time']= timestamp_to_datetime(eth['Close time'])\n",
    "eth[['Open', 'High', 'Low', 'Close', 'Volume']] = eth[['Open', 'High', 'Low', 'Close', 'Volume']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a0a3a28-aaea-4134-9d25-09911fd16d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = eth.sort_values('Open time')\n",
    "eth['Close'] = eth.Close.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247111fb-9550-4414-9b27-28878ed1544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/r2326rms4l37yskjs2yv3mv80000gn/T/ipykernel_10283/3081666131.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  btc_1['y'] = btc_1.Close.shift(-1)\n"
     ]
    }
   ],
   "source": [
    "btc['obv'] = ta.obv(btc.Close,btc.Volume)\n",
    "btc_1 = btc[['Open time','Open','High','Low','Close','Volume','Number of trades','obv']]\n",
    "btc_1['y'] = btc_1.Close.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb73d9ee-cb99-4db2-9212-8e018af500f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_1['log_ret'] = np.log(btc_1.Close) - np.log(btc_1.Close.shift(1))\n",
    "btc_1['log_ret_y'] = btc_1.log_ret.shift(-1)\n",
    "btc_1['open_t-1'] = btc_1.Open.shift(1)\n",
    "btc_1['high_t-1'] = btc_1.High.shift(1)\n",
    "btc_1['low_t-1'] = btc_1.Low.shift(1)\n",
    "btc_1['close_t-1'] = btc_1.Close.shift(1)\n",
    "btc_1['volume_t-1'] = btc_1.Volume.shift(1)\n",
    "btc_1['obv_t-1'] = btc_1.obv.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7552f4ee-4d52-43b1-a937-ef9171b6d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: open t-1, high t-1, low t-1, close t-1, volume t-1, open\n",
    "# y_predict: Close, log_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8800042-2444-47f2-8047-5cc7221e0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = btc_1[['open_t-1','high_t-1','low_t-1','close_t-1','volume_t-1','obv_t-1','Open','Close','log_ret']]\n",
    "df_btc = df_btc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afabdab2-4df0-46ea-886e-8afc621bf004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_t-1</th>\n",
       "      <th>high_t-1</th>\n",
       "      <th>low_t-1</th>\n",
       "      <th>close_t-1</th>\n",
       "      <th>volume_t-1</th>\n",
       "      <th>obv_t-1</th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>7195.24</td>\n",
       "      <td>7196.25</td>\n",
       "      <td>7175.46</td>\n",
       "      <td>7177.02</td>\n",
       "      <td>511.814901</td>\n",
       "      <td>5.118149e+02</td>\n",
       "      <td>7176.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>7176.47</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7175.71</td>\n",
       "      <td>7216.27</td>\n",
       "      <td>883.052603</td>\n",
       "      <td>1.394868e+03</td>\n",
       "      <td>7215.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>7215.52</td>\n",
       "      <td>7244.87</td>\n",
       "      <td>7211.41</td>\n",
       "      <td>7242.85</td>\n",
       "      <td>655.156809</td>\n",
       "      <td>2.050024e+03</td>\n",
       "      <td>7242.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>7242.66</td>\n",
       "      <td>7245.00</td>\n",
       "      <td>7220.00</td>\n",
       "      <td>7225.01</td>\n",
       "      <td>783.724867</td>\n",
       "      <td>1.266299e+03</td>\n",
       "      <td>7225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>7225.00</td>\n",
       "      <td>7230.00</td>\n",
       "      <td>7215.03</td>\n",
       "      <td>7217.27</td>\n",
       "      <td>467.812578</td>\n",
       "      <td>7.984869e+02</td>\n",
       "      <td>7217.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47119</th>\n",
       "      <td>83605.11</td>\n",
       "      <td>85120.00</td>\n",
       "      <td>83196.71</td>\n",
       "      <td>84440.97</td>\n",
       "      <td>2582.555500</td>\n",
       "      <td>1.336630e+06</td>\n",
       "      <td>84440.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47120</th>\n",
       "      <td>84440.97</td>\n",
       "      <td>84810.35</td>\n",
       "      <td>84209.84</td>\n",
       "      <td>84449.99</td>\n",
       "      <td>1656.894460</td>\n",
       "      <td>1.338287e+06</td>\n",
       "      <td>84450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47121</th>\n",
       "      <td>84450.00</td>\n",
       "      <td>84795.03</td>\n",
       "      <td>83600.00</td>\n",
       "      <td>84191.27</td>\n",
       "      <td>2215.505490</td>\n",
       "      <td>1.336072e+06</td>\n",
       "      <td>84190.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47122</th>\n",
       "      <td>84190.51</td>\n",
       "      <td>84596.00</td>\n",
       "      <td>84000.17</td>\n",
       "      <td>84258.37</td>\n",
       "      <td>862.301630</td>\n",
       "      <td>1.336934e+06</td>\n",
       "      <td>84258.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47123</th>\n",
       "      <td>84258.38</td>\n",
       "      <td>84481.14</td>\n",
       "      <td>83888.00</td>\n",
       "      <td>84149.98</td>\n",
       "      <td>650.296710</td>\n",
       "      <td>1.336284e+06</td>\n",
       "      <td>84149.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45232 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open_t-1  high_t-1   low_t-1  close_t-1   volume_t-1       obv_t-1  \\\n",
       "3911    7195.24   7196.25   7175.46    7177.02   511.814901  5.118149e+02   \n",
       "3912    7176.47   7230.00   7175.71    7216.27   883.052603  1.394868e+03   \n",
       "3913    7215.52   7244.87   7211.41    7242.85   655.156809  2.050024e+03   \n",
       "3914    7242.66   7245.00   7220.00    7225.01   783.724867  1.266299e+03   \n",
       "3915    7225.00   7230.00   7215.03    7217.27   467.812578  7.984869e+02   \n",
       "...         ...       ...       ...        ...          ...           ...   \n",
       "47119  83605.11  85120.00  83196.71   84440.97  2582.555500  1.336630e+06   \n",
       "47120  84440.97  84810.35  84209.84   84449.99  1656.894460  1.338287e+06   \n",
       "47121  84450.00  84795.03  83600.00   84191.27  2215.505490  1.336072e+06   \n",
       "47122  84190.51  84596.00  84000.17   84258.37   862.301630  1.336934e+06   \n",
       "47123  84258.38  84481.14  83888.00   84149.98   650.296710  1.336284e+06   \n",
       "\n",
       "           Open  \n",
       "3911    7176.47  \n",
       "3912    7215.52  \n",
       "3913    7242.66  \n",
       "3914    7225.00  \n",
       "3915    7217.26  \n",
       "...         ...  \n",
       "47119  84440.97  \n",
       "47120  84450.00  \n",
       "47121  84190.51  \n",
       "47122  84258.38  \n",
       "47123  84149.99  \n",
       "\n",
       "[45232 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_btc_x = df_btc.iloc[:,:-2]\n",
    "df_btc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be1b6f28-d783-4c50-ac69-33b11094ab45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_modified = []\n",
    "for i in range(df_btc_x.shape[0]-24):\n",
    "    x = df_btc_x.iloc[i:i+24]\n",
    "    X_modified.append(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da51fa10-122c-4d5a-bc5d-af0c096a7d1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "close_mod = []\n",
    "for i in range(24,df_btc_x.shape[0]):\n",
    "    x = df_btc['Close'].iloc[i]\n",
    "    close_mod.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb3a24db-a3f9-4d88-99e0-59b2337fb087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logret_mod = []\n",
    "for i in range(24,df_btc_x.shape[0]):\n",
    "    x = df_btc['log_ret'].iloc[i]\n",
    "    logret_mod.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82308a0f-36b8-4d48-a627-a8a85ff7b8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45208, 24, 7)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_modified).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87ca15c6-e0a6-4fe7-a36f-47a87a8e23e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45208,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(close_mod).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a2102f4-db31-4a5f-99d2-6128b47d365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c21e7dc-da78-4f4d-9f89-26efcb7e8c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_mod_tensor = torch.tensor(X_modified, dtype=torch.float32)\n",
    "close_tensor = torch.tensor(close_mod, dtype=torch.float32)\n",
    "logret_tensor = torch.tensor(logret_mod, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4d1c9a02-a1f0-4937-bef2-2a7e6ad05c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_tensor = close_tensor.view(-1,1)\n",
    "logret_tensor = logret_tensor.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "561507ce-7270-43b4-9edf-bbf7138d8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the split ratio (e.g., 80% train, 20% test)\n",
    "train_size = 0.8\n",
    "\n",
    "# Create train/test splits\n",
    "X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = train_test_split(\n",
    "    X_mod_tensor, close_tensor,\n",
    "    train_size=train_size, \n",
    "    shuffle=False,  # Set to False if working with time series data\n",
    "    random_state=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2183da0f-88c2-4407-b530-4d954da6386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a7b84a1e-6deb-44e0-875a-10fd264b8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # You can adjust this based on your needs\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aa3ad28a-d4e2-4242-85bb-d09fbda6f742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 1131\n",
      "Number of batches in test_loader: 283\n"
     ]
    }
   ],
   "source": [
    "# Number of batches in train_loader\n",
    "num_train_batches = len(train_loader)\n",
    "print(\"Number of batches in train_loader:\", num_train_batches)\n",
    "\n",
    "# Number of batches in test_loader\n",
    "num_test_batches = len(test_loader)\n",
    "print(\"Number of batches in test_loader:\", num_test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb499885-1a0a-4581-9aed-47f7bb9b4c58",
   "metadata": {},
   "source": [
    "# Setting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "170a68d5-246b-4c8b-8db3-c0edbdc1f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "92957d0b-7fa3-4a8e-9671-8e977e27abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=X_train_tensor.shape[-1], hidden_size_1=32, hidden_size_2=64, hidden_size_3=16, output_size=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # First LSTM layer\n",
    "        self.layer1 = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size_1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        self.layer2 = nn.RNN(input_size=hidden_size_1,\n",
    "                          hidden_size=hidden_size_2,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        # Third LSTM layer\n",
    "        self.layer3 = nn.GRU(input_size=hidden_size_2,\n",
    "                          hidden_size=hidden_size_3,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        # Final linear layer\n",
    "        self.fc = nn.Linear(hidden_size_3, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reshape input if it's not in the right format\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(1)  # Add sequence length dimension\n",
    "            \n",
    "        # First LSTM layer\n",
    "        out, _ = self.layer1(x)\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        out, _ = self.layer2(out)\n",
    "        \n",
    "        # Third LSTM layer\n",
    "        out, _ = self.layer3(out)\n",
    "        \n",
    "        # Take the last output and pass through final linear layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a756a529-b511-43ce-bea4-f5745d23f72b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialized\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
    "model_0 = LSTMModel()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
    "# list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3db92-9bed-4362-a5fc-ac6dbee44597",
   "metadata": {},
   "source": [
    "### Setting Loss Function and Optimizer for NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "160b2527-c89f-44f7-9f50-ac72c63b7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09ade34a-40e4-4d1c-aa17-fb890864122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e4c1b075-e789-4837-b63d-d9aca461095e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.000000 | MSE Train Loss: 1091427659.761273 | MSE Test Loss: 5681263748.070671\n",
      "Epoch: 10.000000 | MSE Train Loss: 1091343036.037135 | MSE Test Loss: 5681056536.424028\n",
      "Epoch: 20.000000 | MSE Train Loss: 1091316552.737401 | MSE Test Loss: 5680988357.201413\n",
      "Epoch: 30.000000 | MSE Train Loss: 1091303040.664898 | MSE Test Loss: 5680953071.717315\n",
      "Epoch: 40.000000 | MSE Train Loss: 1091293012.178603 | MSE Test Loss: 5680927371.307421\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Create empty loss lists to track values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "epoch_start_time = time.time()  # Start time for total training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_0.train()  # Put model in training mode\n",
    "    train_loss = 0  # Track total training loss for the epoch\n",
    "    iteration = 0\n",
    "    # Iterate over batches in the training DataLoader\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # 1. Forward pass on train data\n",
    "        y_pred = model_0(X_batch)\n",
    "\n",
    "        # 2. Calculate the loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        # 3. Zero grad of the optimizer clears the gradients of all optimized tensors.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backwards\n",
    "        # This function computes the gradients of the loss with respect to the model parameters using backpropagation.\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Progress the optimizer\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the training loss for the epoch\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    ### Testing\n",
    "    model_0.eval()  # Put the model in evaluation mode\n",
    "    y_preds = []\n",
    "    test_loss = 0  # Track total testing loss for the epoch\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Iterate over batches in the test DataLoader\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            # 1. Forward pass on test data\n",
    "            test_pred = model_0(X_batch)\n",
    "\n",
    "            # 2. Calculate loss on test data\n",
    "            test_loss += loss_fn(test_pred, y_batch).item()\n",
    "\n",
    "        # Calculate average testing loss for the epoch\n",
    "        test_loss /= len(test_loader)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(train_loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch:.6f} | MSE Train Loss: {train_loss:.6f} | MSE Test Loss: {test_loss}\")\n",
    "\n",
    "# total_time = time.time() - epoch_start_time\n",
    "# print(f\"\\nTotal training time: {total_time:.2f} seconds, batch size is {batch_size} and epoch is {epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab017209-7b49-416b-b83c-1022ab2051d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([36166, 1])\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_0.eval()\n",
    "y_train_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for X_batch, _ in train_loader:\n",
    "        y_pred = model_0(X_batch)\n",
    "        y_train_preds.append(y_pred)\n",
    "\n",
    "# Concatenate all predictions into a single tensor\n",
    "y_train_preds = torch.cat(y_train_preds)\n",
    "\n",
    "print(\"Predictions shape:\", y_train_preds.shape)  # Should be (2583, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "105c0171-6e42-457f-876b-3f0358ae88d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([9042, 1])\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_0.eval()\n",
    "y_preds = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for X_batch, _ in test_loader:\n",
    "        y_pred = model_0(X_batch)\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "# Concatenate all predictions into a single tensor\n",
    "y_preds = torch.cat(y_preds)\n",
    "\n",
    "print(\"Predictions shape:\", y_preds.shape)  # Should be (2583, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4b1a1285-9527-4bf1-9cb9-cccd488d421d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36166, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_train_np = y_train_preds.numpy()\n",
    "prediction_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f1ac7f7e-2c8f-48f7-9669-f3191bfdc63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9042, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_np = y_preds.numpy()\n",
    "prediction_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5952e52d-177b-48ce-bc8c-8fd160d191fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2477334],\n",
       "       [3.247842 ],\n",
       "       [3.247944 ],\n",
       "       ...,\n",
       "       [3.2540972],\n",
       "       [3.2540972],\n",
       "       [3.2540972]], shape=(45208, 1), dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concat((prediction_train_np,prediction_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1d6d77f7-567b-4645-b839-ad9d44aa8edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7190.9902],\n",
       "        [ 7169.0200],\n",
       "        [ 7129.6099],\n",
       "        ...,\n",
       "        [84258.3672],\n",
       "        [84149.9766],\n",
       "        [84349.9375]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c69c40-f19f-4f67-a8b3-83e684b895a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
